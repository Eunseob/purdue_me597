{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Lab 10.3 Machine Learning 2 - Machine Learning Implementation to Edge Device\n","\n","# Building Up The Entire Monitoring System\n"],"metadata":{"id":"lPmkFffXOQh2"}},{"cell_type":"markdown","source":["## 3.1 MTConnect Data Stream\n","\n","\n","Let’s move on to the last step for the entire smart IIoT monitoring system. In this section, we will integrate each monitoring part we practiced in all previous labs into a single system to realize a real-time web-based monitoring system as Figure 1. In the previous section of this lab, we practiced the use of the machine learning model using TensorFlow on Raspberry Pi. In this part, let’s make MTConnect data stream including ML results based on the model. The schematic and the data items are shown in Figure 7. \n","\n","![picture](https://github.com/hewp84/tinyml/blob/main/img/L10_Figure7.png?raw=true)\n","\n","*Figure 7 Schematic and data items of MTConnect*\n","\n","The examples of ‘agent.cfg’ and ‘device.xml’ are Figure 8 and Figure 9, respectively. You may have different XML data structure or data item definitions. Also, you can check the example of MTConnect agent running on the server computer: http://me597server1.ecn.purdue.edu:5000/.\n","\n","![picture](https://github.com/hewp84/tinyml/blob/main/img/L10_Figure8.png?raw=true)\n","\n","*Figure 8 front part of 'agent.cfg'*\n","\n","![picture](https://github.com/hewp84/tinyml/blob/main/img/L10_Figure9.png?raw=true)\n","\n","*Figure 9 'device.xml'*"],"metadata":{"id":"lDBDyGriOZpq"}},{"cell_type":"markdown","source":["### Task 3.1\n","\n","Run MTConnect agent on Raspberry Pi with the XML structure and data items defined above. \n","\n","  * Please note that the command to run MTConnect agent is ‘*sudo ./agent*’ in the same directory of the execution file. \n","\n","  * The ‘*agent.cfg*’ and ‘*device.xml*’ must be in the same directory. \n","\n","  * To apply the schema and style in MTConnect agent, ‘*/schema*’ and ‘*/styles*' must be in the same directory as well. \n","\n"],"metadata":{"id":"g7757kKiOidh"}},{"cell_type":"markdown","source":["### Task 3.2\n","\n","Capture ‘/current’ response from the MTConnect agent as Figure 10 and attach it to the report. \n","\n","---\n","\n","Place your screenshot here\n","\n","---"],"metadata":{"id":"vMDsjgi3478I"}},{"cell_type":"markdown","source":["![picture](https://github.com/hewp84/tinyml/blob/main/img/L10_Figure10.png?raw=true)\n","\n","*Figure 10 MTConnect agent ‘/current’ response without MTConnect adapter*\n","\n","The next is to run MTConnect adapter. The sample MTConnect adapter based on the previous section is prepared, ‘lab10_adapter_sample.py’, on Brightspace. The sample is incomplete as is. **Please note that to run MTConnect adapter in this case, ‘data_item.py’, ‘mtconnect_adapter.py’ modules (on Brightspace), and ‘/model’ and sub-directory for your autoencoder model must be in the same directory of the MTConnect adapter Python script**. Perform TASK 6 to finish MTConnect data stream."],"metadata":{"id":"qYMiQ46nOmIK"}},{"cell_type":"markdown","source":["#### Task 3.2\n","\n","Complete the sample script (*‘lab10_adapter_sample.py’*) and then run MTConnect adapter. \n","\n","  * You need to modify the variables wrapped in asteriks below. Also, you need to change the '???' parameters to the appropriate parameters. \n","\n","  * If you have a different XML structure and data items from the example, you must change other parts of the sample script as well. \n","\n","\n","---\n","\n","**Python - Python3 (\"Main of 'lab10_adapter_sample.py')**\n","\n","```\n","if __name__ == \"__main__\":\n","    *model_path* = \"models/YourModelDirectory/\" # model file directory, you must change this!\n","    *model* = tf.keras.models.load_model(model_path) # load the model from the path above\n","    *threshold* =  # float: threshold (MAE loss) for the ML model\n","    *min_val* =  # float: minimum value for normalization\n","    *max_val* =  # float: maximum value for normalization\n","    \n","    # start MTConnect Adapter\n","    MTConnectAdapter(???, ???) # Args: host ip, port number\n","\n","\n","```\n","\n","---\n","\n","\n","---\n","\n","**Python - Python3 (Part of \"MTConnectAdapter\" class of 'lab10_adapter_sample.py')**\n","\n","```\n","    def adapter_stream(self):\n","        while True:\n","            try:\n","                x, y, z = measureData(acc,1000) # x=x-axis, y=y-axis, z-axis acceleration array\n","                *input_feature* = # your input feature\n","                input_feature_normalized = tensorNormalization(input_feature, ???, ???) # normalized input feature\n","                result = predict(model, *FINAL_FEATURE_INPUT*, threshold)\n","                x_rms = timeFeatures(x)[2] # calculate rms of x-axis\n","                *y_rms* =  # calculate rms of y-axis\n","                *z_rms* =  # calculate rms of z-axis\n","                mae = result[?] # mean absolute error (loss) of the model\n","                \n","                if *AFF is running*:\n","                    execution = 'ACTIVE'\n","                    if *AFF is normal*:\n","                        condition = 'NORMAL'\n","                    else:\n","                        condition = 'ABNORMAL'\n","                else:\n","                    execution = 'STOPPED'\n","                    condition = 'UNAVAILABLE'\n","\n","                now = datetime.datetime.now() # get current data time\n","                \n","                self.adapter.begin_gather() # start to collection\n","                \n","                self.Xacc.set_value(str(???))\n","                self.Yacc.set_value(str(???))\n","                self.Zacc.set_value(str(???))\n","                self.execution.set_value(str(???))\n","                self.condition.set_value(str(???))\n","                self.mae.set_value(str(???))\n","                \n","                self.adapter.complete_gather() # end of collection\n","\n","```\n","\n","---\n"],"metadata":{"id":"NG_euFkzOpRj"}},{"cell_type":"markdown","source":["### Task 3.3\n","\n","Capture ‘/current’ response from the MTConnect agent as Figure 11 and attach it to the report. \n","\n","  * Confirm if every data item works as expected by running the AFF. \n","\n","---\n","\n","Place your screenshot here\n","\n","---\n","\n","![picture](https://github.com/hewp84/tinyml/blob/main/img/L10_Figure11.png?raw=true)\n","\n","*Figure 11 MTConnect agent ‘/current’ response with MTConnect adapter*\n"],"metadata":{"id":"RbRxVZpR6UFZ"}},{"cell_type":"markdown","source":["Please continue to [Lab 10.4 here](L10_Colab4.ipynb).\n"],"metadata":{"id":"bPZfbVTwOwKL"}}]}