{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<a href=\"https://githubtocolab.com/Eunseob/purdue_me597/blob/main/lab/lab8/PL8_Colab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"metadata":{"id":"5281fvwwRwMP"}},{"cell_type":"markdown","source":["# Prelab 8.3 Classifying Air-tight Vacuum and Air-leak Vacuum Data using Autoencoders for Anomaly Detection: Y and Z-axis"],"metadata":{"id":"m6re7z0ApOUT"}},{"cell_type":"code","source":["# This command will install TensorFlow 2.2.0 on the Google Colab virtual environment.\n","# This takes a couple of minutes\n","!pip install tensorflow==2.2.0"],"metadata":{"id":"EA5-Qgs0heWl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The output must be 'TensorFlow Version is 2.2.0'\n","import tensorflow as tf\n","\n","print('TensorFlow Version is', tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdWob_g4iMn5","executionInfo":{"status":"ok","timestamp":1676559379578,"user_tz":300,"elapsed":6795,"user":{"displayName":"Eunseob Kim","userId":"10891288376510921037"}},"outputId":"adee6ef5-0086-4f39-cbdd-bda5a0b4ee67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow Version is 2.2.0\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import scipy.fftpack\n","from tensorflow import keras\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import layers, losses\n","from tensorflow.keras.models import Model"],"metadata":{"id":"q2eFAUL-kenG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Copying raw data from github dataset file\n","url = 'https://github.com/Eunseob/purdue_me597/blob/main/lab/lab8/Prelab8_data.csv?raw=true'\n","#df is the variable where the data is stored\n","df = pd.read_csv(url)\n","\n","#Data selection\n","# X-axis: 'Xacc array [m/s2]'\n","# Y-axis: 'Yacc array [m/s2]'\n","# Z-axis: 'Zacc array [m/s2]'\n","# If you want to use x-axis (X-axis),\n","# AXIS = 'Xacc array [m/s2]'\n","AXIS =  #Pick and write the axis you want to work <-----------------------------------------------------------------------------\n","\n","#Exploding the values contained in selected column and converting the string values into float values\n","df = pd.concat([df['Condition'],df[AXIS].str.split(' ', expand=True).astype(float)], axis=1)\n","ds = df.copy()\n","#Converting the Classifier into binary values\n","ds.loc[df['Condition'] == 'Vacuuming', 'Status'] = 1\n","ds.loc[df['Condition'] == 'Air_leakage', 'Status'] = 0\n","ds.drop('Condition', axis=1, inplace=True)\n","\n","#Data transformation\n","\n","raw_data = ds.values\n","# The last element contains the labels\n","labels = raw_data[:, -1]\n","\n","# The other data points are the vacuum accelerometer data\n","data = raw_data[:, 0:-1]\n","\n","train_data, test_data, train_labels, test_labels = train_test_split(\n","    data, labels, test_size=0.2, random_state=21\n",")\n","#Normalizing the values of the dataset \n","min_val = tf.reduce_min(train_data)\n","max_val = tf.reduce_max(train_data)\n","\n","train_data = (train_data - min_val) / (max_val - min_val)\n","test_data = (test_data - min_val) / (max_val - min_val)\n","\n","train_data = tf.cast(train_data, tf.float32)\n","test_data = tf.cast(test_data, tf.float32)\n","#Splitting the dataset based on classification: train_labels: Vacuuming, ~train_labels: Air Leakage\n","train_labels = train_labels.astype(bool)\n","test_labels = test_labels.astype(bool)\n","\n","normal_train_data = train_data[train_labels]\n","normal_test_data = test_data[test_labels]\n","\n","anomalous_train_data = train_data[~train_labels]\n","anomalous_test_data = test_data[~test_labels]\n","\n","portion_of_anomaly_in_training = 0.1 #10% of training data will be anomalies\n","end_size = int(len(normal_train_data)/(10-portion_of_anomaly_in_training*10))\n","combined_train_data = np.append(normal_train_data, anomalous_test_data[:end_size], axis=0)\n","combined_train_data.shape"],"metadata":{"id":"b6qQDn-mppUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plotting sample of normal data\n","plt.grid()\n","plt.plot(np.arange(1000), normal_train_data[0])\n","plt.title(\"A Normal vibration signal\")\n","plt.show()"],"metadata":{"id":"OTcxXnheqK7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plotting sample of anomalous data\n","plt.grid()\n","plt.plot(np.arange(1000), anomalous_train_data[0])\n","plt.title(\"An abnormal vibration signal (Air leakage)\")\n","plt.show()"],"metadata":{"id":"itjt15aJqPcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Creating the artificial neural network using Autoencoder\n","EMBEDDING_SIZE =  #Define how many neurons in the inner layer   <-----------------------------------------------------------------------------\n","class AnomalyDetector(Model):\n","  def __init__(self):\n","    super(AnomalyDetector, self).__init__()\n","    self.encoder = tf.keras.Sequential([\n","      layers.Dense(32, activation=\"relu\"),\n","      layers.Dense(16, activation=\"relu\"),\n","      layers.Dense(EMBEDDING_SIZE, activation=\"relu\")]) # Smallest Layer Defined Here\n","    \n","    self.decoder = tf.keras.Sequential([\n","      layers.Dense(16, activation=\"relu\"),\n","      layers.Dense(32, activation=\"relu\"),\n","      layers.Dense(1000, activation=\"sigmoid\")])\n","    \n","  def call(self, x):\n","    encoded = self.encoder(x)\n","    decoded = self.decoder(encoded)\n","    return decoded\n","\n","autoencoder = AnomalyDetector()\n","print(\"Chosen Embedding Size: \", EMBEDDING_SIZE)\n","\n","autoencoder.compile(optimizer='adam', loss='mae')\n","#Training the model. \n","history = autoencoder.fit(normal_train_data, normal_train_data, \n","          epochs=200, \n","          batch_size=200,\n","          validation_data=(test_data, test_data),\n","          shuffle=True)"],"metadata":{"id":"Kv4QATAGqWdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plotting the evolution of training and validation loss\n","plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n","plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n","plt.legend()"],"metadata":{"id":"aMkwSPT5ql6n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How are the loss functions looking? Is there a need to adjust the EMBEDDING SIZE or the epochs in order to minimize it more?"],"metadata":{"id":"GclUcPaGq0i8"}},{"cell_type":"code","source":["#Plotting True positive and false positive rate assessment\n","reconstructions = autoencoder(test_data)\n","loss = tf.keras.losses.mae(reconstructions, test_data)\n","fpr = []\n","tpr = []\n","#the test labels are flipped to match how the roc_curve function expects them.\n","flipped_labels = 1-test_labels \n","fpr, tpr, thresholds = roc_curve(flipped_labels, loss)\n","plt.figure()\n","lw = 2\n","plt.plot(fpr, tpr, color='darkorange',\n","         lw=lw, label='ROC curve ')\n","plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver operating characteristic example')\n","plt.legend(loc=\"lower right\")\n","\n","# plot some thresholds\n","thresholds_every=20\n","thresholdsLength = len(thresholds)\n","colorMap=plt.get_cmap('jet', thresholdsLength)\n","for i in range(0, thresholdsLength, thresholds_every):\n","  threshold_value_with_max_four_decimals = str(thresholds[i])[:5]\n","  plt.scatter(fpr[i], tpr[i], c='black')\n","  plt.text(fpr[i] - 0.03, tpr[i] + 0.005, threshold_value_with_max_four_decimals, fontdict={'size': 15});\n","\n","plt.show()"],"metadata":{"id":"_NxQaO2srfhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["roc_auc = auc(fpr, tpr)\n","print(roc_auc)"],"metadata":{"id":"xiPVc0Iqr4Sc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold =  #Assign a value labeled in black in the ROC graph   <-----------------------------------------------------------------------------\n","def predict(model, data, threshold):\n","  reconstructions = model(data)\n","  loss = tf.keras.losses.mae(reconstructions, data)\n","  return tf.math.less(loss, threshold), loss\n","\n","def print_stats(predictions, labels):\n","  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n","  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n","  print(\"Recall = {}\".format(recall_score(labels, predictions)))\n","  preds, scores = predict(autoencoder, test_data, threshold)\n","print_stats(preds, test_labels)"],"metadata":{"id":"kJ7bA8P5sB4G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Task 3.1\n","How can you compare the models using data from the X-axis and Y-axis data? which one does a better job classifying? Explain your reasoning."],"metadata":{"id":"OLx_p3Vpvku1"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","Write down your answer to Task 3.1 here.\n","\n","---\n"],"metadata":{"id":"2iScEU_svtiA"}},{"cell_type":"markdown","source":["##Working in the Z-axis\n","\n","Recycle the code from the previous two dimensions, to build a model using the data from the Z-axis."],"metadata":{"id":"R3LLtcnWuq_P"}},{"cell_type":"code","source":["#Your code here\n","\n","\n","\n","\n","#"],"metadata":{"id":"Lwf48FZEvT28"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Task 3.2\n","Which model (X, Y, or Z) would you choose to classify normal and abnormal readings for the vacuum problem? Explain your reasoning."],"metadata":{"id":"kFnJIB9Bv4ZA"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","Write down your answer to Task 3.2 here.\n","\n","---\n"],"metadata":{"id":"c9-EEbVhv4ZB"}},{"cell_type":"markdown","source":["### Task 3.3\n","What other data transformations/extractions would you consider to build a model to classify normal and abnormal data on the vacuum problem?"],"metadata":{"id":"C7_qAO3owI-H"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","Write down your answer to Task 3.3 here.\n","\n","---\n"],"metadata":{"id":"SR7FGthRwI-I"}},{"cell_type":"markdown","source":["<br></br>\n","\n","Get back to [Lab Index Page](https://colab.research.google.com/github/Eunseob/purdue_me597/blob/main/index.ipynb)"],"metadata":{"id":"KdwsmuFEwZV2"}}]}