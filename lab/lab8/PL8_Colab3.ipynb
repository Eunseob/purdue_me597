{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://githubtocolab.com/Eunseob/purdue_me597/blob/main/lab/lab8/PL8_Colab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "5281fvwwRwMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prelab 8.3 Classifying Air-tight Vacuum and Air-leak Vacuum Data using Autoencoders for Anomaly Detection: Y and Z-axis"
      ],
      "metadata": {
        "id": "m6re7z0ApOUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Because recent [Colab update on March 8, 2023](https://medium.com/google-colab/colab-updated-to-python-3-9-2593f8b1eb79), the default Python version in Colab is 3.9. This results in [TensorFlow version compatibility](https://www.tensorflow.org/install/source#tested_build_configurations) issues between Colab and Raspberry Pi since Raspberry Pi (Raspberry Pi OS version 10, Buster) uses Python 3.7 as default. Therefore, before we get started, let's first set up Python 3.7 and then install other required and compatible packages on Colab. This takes around 2 minutes.\n",
        "\n",
        "Note that after you install TensorFlow 2.2.0 in 10th code block, you will see '**RESTART RUNTIME**' button as captured below. Please click the button and move to the next cell so that installed package is able to be applied to Colab session.\n",
        "\n",
        "**In addition, please make sure that you perform the same procedure in the new Colab file if you want to develop your own machine-learning models and train them for implementation on Raspberry Pi.**\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://github.com/Eunseob/purdue_me597/blob/main/lab/img/prelab10_img0.png?raw=true\" width=\"60%\">\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "HRnDLkJCrJuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep the packages update\n",
        "!sudo apt-get update -y\n",
        "!sudo apt upgrade -y"
      ],
      "metadata": {
        "id": "05T5XlEhE4ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install Python3.7 on virtual session\n",
        "!sudo apt-get install python3.7 python3.7-dev python3.7-distutils libpython3.7-dev"
      ],
      "metadata": {
        "id": "nTq_-wtrE8KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 2"
      ],
      "metadata": {
        "id": "R4ZaolEDFTA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check that it points at the right location\n",
        "# The version musb be Python 3.7.X\n",
        "!python3 --version"
      ],
      "metadata": {
        "id": "gFyKVaL3FY7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install pip\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall"
      ],
      "metadata": {
        "id": "kN1av53XFbqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#install colab's dependencies\n",
        "!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor"
      ],
      "metadata": {
        "id": "n6XTSCzoFrr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3.7-distutils"
      ],
      "metadata": {
        "id": "YKVWCw0pLq0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# link to the old google package\n",
        "!ln -s /usr/local/lib/python3.10/dist-packages/google \\\n",
        "       /usr/local/lib/python3.7/dist-packages/google\n"
      ],
      "metadata": {
        "id": "GWINh5tZF0qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IPython no longer exposes traitlets like this, it's a separate package now\n",
        "!sed -i \"s/from IPython.utils import traitlets as _traitlets/import traitlets as _traitlets/\" /usr/local/lib/python3.7/dist-packages/google/colab/*.py\n",
        "!sed -i \"s/from IPython.utils import traitlets/import traitlets/\" /usr/local/lib/python3.7/dist-packages/google/colab/*.py"
      ],
      "metadata": {
        "id": "rUHwPd-9F3TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install tensorflow version 2.2.0\n",
        "# After running this, you have to reconnect the session by clicking 'RESTART RUNTIME' button at the end of the output cell \n",
        "!pip install tensorflow==2.2.0\n",
        "!pip install protobuf==3.20.1"
      ],
      "metadata": {
        "id": "4L1cROSEGD93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the installed tensorflow version\n",
        "# The output cell must be 'TensorFlow Version is 2.2.0'\n",
        "import tensorflow as tf\n",
        "\n",
        "print('TensorFlow Version is', tf.__version__)"
      ],
      "metadata": {
        "id": "Uq1a_cmdoXAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c9fb25-b6cf-45a1-f0b4-57a370abcc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version is 2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# required Python packages for this colab\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install scipy==1.4.1\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "VO_nLYFLHNnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The output will be 'TensorFlow Version is 2.11.0'\n",
        "# However, in the following lab, we have to install TensorFlow version 2.2.0.\n",
        "import tensorflow as tf\n",
        "\n",
        "print('TensorFlow Version is', tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdWob_g4iMn5",
        "outputId": "9156981b-e98a-441e-beb6-3852a75e89c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version is 2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.fftpack\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "q2eFAUL-kenG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copying raw data from github dataset file\n",
        "url = 'https://github.com/Eunseob/purdue_me597/blob/main/lab/lab8/Prelab8_data.csv?raw=true'\n",
        "#df is the variable where the data is stored\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "#Data selection\n",
        "# X-axis: 'Xacc array [m/s2]'\n",
        "# Y-axis: 'Yacc array [m/s2]'\n",
        "# Z-axis: 'Zacc array [m/s2]'\n",
        "# If you want to use x-axis (X-axis),\n",
        "# AXIS = 'Xacc array [m/s2]'\n",
        "AXIS =  #Pick and write the axis you want to work <-----------------------------------------------------------------------------\n",
        "\n",
        "#Exploding the values contained in selected column and converting the string values into float values\n",
        "df_new = pd.concat([df['Condition'],df[AXIS].str.split(' ', expand=True).astype(float)], axis=1)\n",
        "ds = df_new.copy()\n",
        "#Converting the Classifier into binary values\n",
        "ds.loc[df['Condition'] == 'Vacuuming', 'Status'] = 1\n",
        "ds.loc[df['Condition'] == 'Air_leakage', 'Status'] = 0\n",
        "ds.drop('Condition', axis=1, inplace=True)\n",
        "\n",
        "#Data transformation\n",
        "\n",
        "raw_data = ds.values\n",
        "# The last element contains the labels\n",
        "labels = raw_data[:, -1]\n",
        "\n",
        "# The other data points are the vacuum accelerometer data\n",
        "data = raw_data[:, 0:-1]\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=21\n",
        ")\n",
        "#Normalizing the values of the dataset \n",
        "min_val = tf.reduce_min(train_data)\n",
        "max_val = tf.reduce_max(train_data)\n",
        "\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "test_data = tf.cast(test_data, tf.float32)\n",
        "#Splitting the dataset based on classification: train_labels: Vacuuming, ~train_labels: Air Leakage\n",
        "train_labels = train_labels.astype(bool)\n",
        "test_labels = test_labels.astype(bool)\n",
        "\n",
        "normal_train_data = train_data[train_labels]\n",
        "normal_test_data = test_data[test_labels]\n",
        "\n",
        "anomalous_train_data = train_data[~train_labels]\n",
        "anomalous_test_data = test_data[~test_labels]\n",
        "\n",
        "portion_of_anomaly_in_training = 0.1 #10% of training data will be anomalies\n",
        "end_size = int(len(normal_train_data)/(10-portion_of_anomaly_in_training*10))\n",
        "combined_train_data = np.append(normal_train_data, anomalous_test_data[:end_size], axis=0)\n",
        "combined_train_data.shape"
      ],
      "metadata": {
        "id": "b6qQDn-mppUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "80f27855-9450-4ff8-ef44-f20617fe6677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-07e1ad6f2c19>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    AXIS =  #Pick and write the axis you want to work <-----------------------------------------------------------------------------\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting sample of normal data\n",
        "plt.grid()\n",
        "plt.plot(np.arange(1000), normal_train_data[0])\n",
        "plt.title(\"A Normal vibration signal\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OTcxXnheqK7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting sample of anomalous data\n",
        "plt.grid()\n",
        "plt.plot(np.arange(1000), anomalous_train_data[0])\n",
        "plt.title(\"An abnormal vibration signal (Air leakage)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "itjt15aJqPcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the artificial neural network using Autoencoder\n",
        "EMBEDDING_SIZE =  #Define how many neurons in the inner layer   <-----------------------------------------------------------------------------\n",
        "class AnomalyDetector(Model):\n",
        "  def __init__(self):\n",
        "    super(AnomalyDetector, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(EMBEDDING_SIZE, activation=\"relu\")]) # Smallest Layer Defined Here\n",
        "    \n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(1000, activation=\"sigmoid\")])\n",
        "    \n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = AnomalyDetector()\n",
        "print(\"Chosen Embedding Size: \", EMBEDDING_SIZE)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mae')\n",
        "#Training the model. \n",
        "history = autoencoder.fit(normal_train_data, normal_train_data, \n",
        "          epochs=200, \n",
        "          batch_size=200,\n",
        "          validation_data=(test_data, test_data),\n",
        "          shuffle=True)"
      ],
      "metadata": {
        "id": "Kv4QATAGqWdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the evolution of training and validation loss\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "aMkwSPT5ql6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How are the loss functions looking? Is there a need to adjust the EMBEDDING SIZE or the epochs in order to minimize it more?"
      ],
      "metadata": {
        "id": "GclUcPaGq0i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting True positive and false positive rate assessment\n",
        "reconstructions = autoencoder(test_data)\n",
        "loss = tf.keras.losses.mae(reconstructions, test_data)\n",
        "fpr = []\n",
        "tpr = []\n",
        "#the test labels are flipped to match how the roc_curve function expects them.\n",
        "flipped_labels = 1-test_labels \n",
        "fpr, tpr, thresholds = roc_curve(flipped_labels, loss)\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve ')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# plot some thresholds\n",
        "thresholds_every=20\n",
        "thresholdsLength = len(thresholds)\n",
        "colorMap=plt.get_cmap('jet', thresholdsLength)\n",
        "for i in range(0, thresholdsLength, thresholds_every):\n",
        "  threshold_value_with_max_four_decimals = str(thresholds[i])[:5]\n",
        "  plt.scatter(fpr[i], tpr[i], c='black')\n",
        "  plt.text(fpr[i] - 0.03, tpr[i] + 0.005, threshold_value_with_max_four_decimals, fontdict={'size': 15});\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_NxQaO2srfhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)"
      ],
      "metadata": {
        "id": "xiPVc0Iqr4Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold =  #Assign a value labeled in black in the ROC graph   <-----------------------------------------------------------------------------\n",
        "def predict(model, data, threshold):\n",
        "  reconstructions = model(data)\n",
        "  loss = tf.keras.losses.mae(reconstructions, data)\n",
        "  return tf.math.less(loss, threshold), loss\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
        "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
        "  print(\"Recall = {}\".format(recall_score(labels, predictions)))\n",
        "  preds, scores = predict(autoencoder, test_data, threshold)\n",
        "print_stats(preds, test_labels)"
      ],
      "metadata": {
        "id": "kJ7bA8P5sB4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.1\n",
        "How can you compare the models using data from the X-axis and Y-axis data? which one does a better job classifying? Explain your reasoning."
      ],
      "metadata": {
        "id": "OLx_p3Vpvku1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Write down your answer to Task 3.1 here.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "2iScEU_svtiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Working in the Z-axis\n",
        "\n",
        "Recycle the code from the previous two dimensions, to build a model using the data from the Z-axis."
      ],
      "metadata": {
        "id": "R3LLtcnWuq_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "Lwf48FZEvT28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.2\n",
        "Which model (X, Y, or Z) would you choose to classify normal and abnormal readings for the vacuum problem? Explain your reasoning."
      ],
      "metadata": {
        "id": "kFnJIB9Bv4ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Write down your answer to Task 3.2 here.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "c9-EEbVhv4ZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.3\n",
        "What other data transformations/extractions would you consider to build a model to classify normal and abnormal data on the vacuum problem?"
      ],
      "metadata": {
        "id": "C7_qAO3owI-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Write down your answer to Task 3.3 here.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "SR7FGthRwI-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "\n",
        "[View the rubric for this prelab](https://colab.research.google.com/github/Eunseob/purdue_me597/blob/main/lab/lab8/PL8_Rubric.ipynb)"
      ],
      "metadata": {
        "id": "gOS09saKRaHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br></br>\n",
        "\n",
        "Get back to [Lab Index Page](https://colab.research.google.com/github/Eunseob/purdue_me597/blob/main/index.ipynb)"
      ],
      "metadata": {
        "id": "KdwsmuFEwZV2"
      }
    }
  ]
}