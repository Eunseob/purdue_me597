{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PL9_Colab3.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prelab 9.3 Classifying Air-tight Vacuum and Air-leak Vacuum Data using Autoencoders for Anomaly Detection: Y and Z dimension"
      ],
      "metadata": {
        "id": "m6re7z0ApOUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import scipy.fftpack\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "q2eFAUL-kenG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copying raw data from github dataset file\n",
        "url = 'https://raw.githubusercontent.com/hewp84/tinyml/main/datasets/Prelab9_data.csv'\n",
        "#df is the variable where the data is stored\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "#Data selection\n",
        "# X-dimension: 'Xacc array [m/s2]'\n",
        "# Y-dimension: 'Yacc array [m/s2]'\n",
        "# Z-dimension: 'Zacc array [m/s2]'\n",
        "DIMENSION =  #Pick and write the dimension you want to work <-----------------------------------------------------------------------------\n",
        "\n",
        "#Exploding the values contained in selected column and converting the string values into float values\n",
        "df = pd.concat([df['Condition'],df[DIMENSION].str.split(' ', expand=True).astype(float)], axis=1)\n",
        "ds = df.copy()\n",
        "#Converting the Classifier into binary values\n",
        "ds.loc[df['Condition'] == 'Vacuuming', 'Status'] = 1\n",
        "ds.loc[df['Condition'] == 'Air_leakage', 'Status'] = 0\n",
        "ds.drop('Condition', axis=1, inplace=True)\n",
        "\n",
        "#Data transformation\n",
        "\n",
        "raw_data = ds.values\n",
        "# The last element contains the labels\n",
        "labels = raw_data[:, -1]\n",
        "\n",
        "# The other data points are the vacuum accelerometer data\n",
        "data = raw_data[:, 0:-1]\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=21\n",
        ")\n",
        "#Normalizing the values of the dataset \n",
        "min_val = tf.reduce_min(train_data)\n",
        "max_val = tf.reduce_max(train_data)\n",
        "\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "test_data = tf.cast(test_data, tf.float32)\n",
        "#Splitting the dataset based on classification: train_labels: Vacuuming, ~train_labels: Air Leakage\n",
        "train_labels = train_labels.astype(bool)\n",
        "test_labels = test_labels.astype(bool)\n",
        "\n",
        "normal_train_data = train_data[train_labels]\n",
        "normal_test_data = test_data[test_labels]\n",
        "\n",
        "anomalous_train_data = train_data[~train_labels]\n",
        "anomalous_test_data = test_data[~test_labels]\n",
        "\n",
        "portion_of_anomaly_in_training = 0.1 #10% of training data will be anomalies\n",
        "end_size = int(len(normal_train_data)/(10-portion_of_anomaly_in_training*10))\n",
        "combined_train_data = np.append(normal_train_data, anomalous_test_data[:end_size], axis=0)\n",
        "combined_train_data.shape"
      ],
      "metadata": {
        "id": "b6qQDn-mppUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting sample of normal data\n",
        "plt.grid()\n",
        "plt.plot(np.arange(1000), normal_train_data[0])\n",
        "plt.title(\"A Normal vibration signal\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OTcxXnheqK7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting sample of anomalous data\n",
        "plt.grid()\n",
        "plt.plot(np.arange(1000), anomalous_train_data[0])\n",
        "plt.title(\"An abnormal vibration signal (Air leakage)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "itjt15aJqPcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the artificial neural network using Autoencoder\n",
        "EMBEDDING_SIZE =  #Define how many neurons in the inner layer   <-----------------------------------------------------------------------------\n",
        "class AnomalyDetector(Model):\n",
        "  def __init__(self):\n",
        "    super(AnomalyDetector, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(EMBEDDING_SIZE, activation=\"relu\")]) # Smallest Layer Defined Here\n",
        "    \n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(16, activation=\"relu\"),\n",
        "      layers.Dense(32, activation=\"relu\"),\n",
        "      layers.Dense(1000, activation=\"sigmoid\")])\n",
        "    \n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = AnomalyDetector()\n",
        "print(\"Chosen Embedding Size: \", EMBEDDING_SIZE)\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mae')\n",
        "#Training the model. \n",
        "history = autoencoder.fit(normal_train_data, normal_train_data, \n",
        "          epochs=200, \n",
        "          batch_size=200,\n",
        "          validation_data=(test_data, test_data),\n",
        "          shuffle=True)"
      ],
      "metadata": {
        "id": "Kv4QATAGqWdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the evolution of training and validation loss\n",
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "aMkwSPT5ql6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How are the loss functions looking? Is there a need to adjust the EMBEDDING SIZE or the epochs in order to minimize it more?"
      ],
      "metadata": {
        "id": "GclUcPaGq0i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting True positive and false positive rate assessment\n",
        "reconstructions = autoencoder(test_data)\n",
        "loss = tf.keras.losses.mae(reconstructions, test_data)\n",
        "fpr = []\n",
        "tpr = []\n",
        "#the test labels are flipped to match how the roc_curve function expects them.\n",
        "flipped_labels = 1-test_labels \n",
        "fpr, tpr, thresholds = roc_curve(flipped_labels, loss)\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve ')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# plot some thresholds\n",
        "thresholds_every=20\n",
        "thresholdsLength = len(thresholds)\n",
        "colorMap=plt.get_cmap('jet', thresholdsLength)\n",
        "for i in range(0, thresholdsLength, thresholds_every):\n",
        "  threshold_value_with_max_four_decimals = str(thresholds[i])[:5]\n",
        "  plt.scatter(fpr[i], tpr[i], c='black')\n",
        "  plt.text(fpr[i] - 0.03, tpr[i] + 0.005, threshold_value_with_max_four_decimals, fontdict={'size': 15});\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_NxQaO2srfhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc = auc(fpr, tpr)\n",
        "print(roc_auc)"
      ],
      "metadata": {
        "id": "xiPVc0Iqr4Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold =  #Assign a value labeled in black in the ROC graph   <-----------------------------------------------------------------------------\n",
        "def predict(model, data, threshold):\n",
        "  reconstructions = model(data)\n",
        "  loss = tf.keras.losses.mae(reconstructions, data)\n",
        "  return tf.math.less(loss, threshold), loss\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
        "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
        "  print(\"Recall = {}\".format(recall_score(labels, predictions)))\n",
        "  preds, scores = predict(autoencoder, test_data, threshold)\n",
        "print_stats(preds, test_labels)"
      ],
      "metadata": {
        "id": "kJ7bA8P5sB4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Q6. How can you compare the models using data from the X-dimension and Y-dimension data? Which one does a better job classifying? Explain your reasoning.\n",
        "\n",
        "Q6 = '' #@param {type:\"string\"}\n",
        "\n",
        "print(Q6)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ug6nmi8quVGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Working in the Z-dimension\n",
        "\n",
        "Recycle the code from the previous two dimensions, to build a model using the data from the Z-dimension."
      ],
      "metadata": {
        "id": "R3LLtcnWuq_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "Lwf48FZEvT28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Q7. Which model (X, Y, or Z) would you choose to classify normal and abnormal readings for the vacuum problem? Explain your reasoning.\n",
        "\n",
        "Q7 = '' #@param {type:\"string\"}\n",
        "\n",
        "print(Q7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "9QzOCc5dvXNh",
        "outputId": "f9aecd14-8374-4111-a3e6-345c52b0c2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Q8. What other data transformations would you consider to build a model to classify normal and abnormal data on the vacuum problem?\n",
        "\n",
        "Q8 = '' #@param {type:\"string\"}\n",
        "\n",
        "print(Q8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mNcMB0yvm0d",
        "outputId": "09ed220b-e2c4-48eb-f018-bae600aa1ddf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}