{"cells":[{"cell_type":"markdown","metadata":{"id":"8H-ayLz77VTC"},"source":["## Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gxNaZWB7VTD"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import scipy.stats as sp\n","import pywt"]},{"cell_type":"code","source":["# Acess to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"KzWNVj117aux"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OOe87dbC7VTE"},"source":[".\n","\n",".\n","\n",".\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jZHZVItO7VTE"},"source":["## Declare the size of feature dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2cjmz1xi7VTF"},"outputs":[],"source":["NoOfData    = 180  # 180 Data for each robotic spot-welding condition (Normal, Abnormal)\n","NoOfSensor  = 3    # 3 Sensor signals: Acceleration, Voltage, Current\n","NoOfFeature = 10   # 10 Feature types: Max, Min, Mean, RMS, Variance, Skewness, Kurtosis, Crest factor, Shape factor, Impulse factor\n","\n","NoOfData, NoOfSensor, NoOfFeature"]},{"cell_type":"markdown","source":["## Load Raw Dataset (360 files)"],"metadata":{"id":"JqYYoU40LdkF"}},{"cell_type":"code","source":["for i in range(NoOfData):\n","    \n","    temp_path1 = 'https://github.com/Eunseob/purdue_me597/blob/main/ml_tutorial/Dataset/Normal_%d?raw=true'%(i+1)   # File path of temporary normal data\n","    temp_path2 = 'https://github.com/Eunseob/purdue_me597/blob/main/ml_tutorial/Dataset/Abnormal_%d?raw=true'%(i+1) # File path of temporary abnormal data\n","\n","    exec(\"Normal_%d   = pd.read_csv(temp_path1 , sep=',' , header=None)\"%(i+1))\n","    exec(\"Abnormal_%d = pd.read_csv(temp_path2 , sep=',' , header=None)\"%(i+1))"],"metadata":{"id":"aAKDUL8LLYQu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7QVCEeC67VTG"},"source":["## Time Domain Feature Extraction\n","- 10 features * 3 sensors = 30 features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ye2DueRB7VTH"},"outputs":[],"source":["# Definition of rms function\n","def rms(x): \n","    return np.sqrt(np.mean(x**2))"]},{"cell_type":"code","source":["# Create empty(0) arrays for normal/abnormal feature dataset (time domain)\n","TimeFeature_Normal   = np.zeros((NoOfSensor*NoOfFeature , NoOfData))\n","TimeFeature_Abnormal = np.zeros((NoOfSensor*NoOfFeature , NoOfData))\n","\n","print(TimeFeature_Normal.shape)\n","print(TimeFeature_Abnormal.shape)\n","\n","TimeFeature_Normal"],"metadata":{"id":"Aql9aRxpHHYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CCW5qEVL7VTH"},"outputs":[],"source":["for i in range(NoOfData):\n","    \n","    # Declare temporary data\n","    exec(\"temp_data1 = Normal_%d\"%(i+1))\n","    exec(\"temp_data2 = Abnormal_%d\"%(i+1))\n","    \n","    # Time domain feature extraction\n","    for j in range(NoOfSensor):\n","        \n","        # Normal features\n","        TimeFeature_Normal[NoOfFeature*j+0, i] = np.max(temp_data1.iloc[:,j+1])\n","        TimeFeature_Normal[NoOfFeature*j+1, i] = np.min(temp_data1.iloc[:,j+1])\n","        TimeFeature_Normal[NoOfFeature*j+2, i] = np.mean(temp_data1.iloc[:,j+1])\n","        TimeFeature_Normal[NoOfFeature*j+3, i] = rms(temp_data1.iloc[:,j+1])\n","        TimeFeature_Normal[NoOfFeature*j+4, i] = np.var(temp_data1.iloc[:,j+1])\n","        TimeFeature_Normal[NoOfFeature*j+5, i] = sp.skew(temp_data1.iloc[:,j+1])\n","        TimeFeature_Normal[NoOfFeature*j+6, i] = sp.kurtosis(temp_data1.iloc[:,j+1])\n","        TimeFeature_Normal[NoOfFeature*j+7, i] = np.max(temp_data1.iloc[:,j+1])/rms(temp_data1.iloc[:,j+1])\n","        TimeFeature_Normal[NoOfFeature*j+8, i] = rms(temp_data1.iloc[:,j+1])/np.mean(np.abs(temp_data1.iloc[:,j+1]))\n","        TimeFeature_Normal[NoOfFeature*j+9, i] = np.max(temp_data1.iloc[:,j+1])/np.mean(np.abs(temp_data1.iloc[:,j+1]))\n","        \n","        # Abnormal features\n","        TimeFeature_Abnormal[NoOfFeature*j+0, i] = np.max(temp_data2.iloc[:,j+1])\n","        TimeFeature_Abnormal[NoOfFeature*j+1, i] = np.min(temp_data2.iloc[:,j+1])\n","        TimeFeature_Abnormal[NoOfFeature*j+2, i] = np.mean(temp_data2.iloc[:,j+1])\n","        TimeFeature_Abnormal[NoOfFeature*j+3, i] = rms(temp_data2.iloc[:,j+1])\n","        TimeFeature_Abnormal[NoOfFeature*j+4, i] = np.var(temp_data2.iloc[:,j+1])\n","        TimeFeature_Abnormal[NoOfFeature*j+5, i] = sp.skew(temp_data2.iloc[:,j+1])\n","        TimeFeature_Abnormal[NoOfFeature*j+6, i] = sp.kurtosis(temp_data2.iloc[:,j+1])\n","        TimeFeature_Abnormal[NoOfFeature*j+7, i] = np.max(temp_data2.iloc[:,j+1])/rms(temp_data2.iloc[:,j+1])\n","        TimeFeature_Abnormal[NoOfFeature*j+8, i] = rms(temp_data2.iloc[:,j+1])/np.mean(np.abs(temp_data2.iloc[:,j+1]))\n","        TimeFeature_Abnormal[NoOfFeature*j+9, i] = np.max(temp_data2.iloc[:,j+1])/np.mean(np.abs(temp_data2.iloc[:,j+1]))\n","        \n","print(TimeFeature_Normal.shape)\n","print(TimeFeature_Abnormal.shape)\n","\n","TimeFeature_Normal"]},{"cell_type":"markdown","metadata":{"id":"-w-zg3r47VTI"},"source":["### Combine Normal and Abnormal feature arrays\n","\n","* axis=0: combine rows\n","* axis=1: combine columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8BnnReJ7VTJ"},"outputs":[],"source":["TimeFeature = np.concatenate([TimeFeature_Normal, TimeFeature_Abnormal] , axis=1)\n","TimeFeature.shape"]},{"cell_type":"markdown","metadata":{"id":"DsHBkzo47VTJ"},"source":[".\n","\n",".\n","\n",".\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jWtCpQaT7VTJ"},"source":["## Frequency Domain Feature Extraction\n","- 10 features * 8 wavelet levels * 3 sensors = 240 features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rW_AAQaW7VTJ"},"outputs":[],"source":["# Wavelet options\n","MotherWavelet = pywt.Wavelet('haar')   # Mother wavelet\n","Level   = 8                            # Wavelet decomposition level"]},{"cell_type":"code","source":["# Create empty(0) arrays for normal/abnormal feature dataset (frequency Domain)\n","FreqFeature_Normal   = np.zeros(shape=(NoOfSensor*NoOfFeature*Level , NoOfData))\n","FreqFeature_Abnormal = np.zeros(shape=(NoOfSensor*NoOfFeature*Level , NoOfData))\n","\n","print(FreqFeature_Normal.shape)\n","print(FreqFeature_Abnormal.shape)\n","\n","FreqFeature_Normal"],"metadata":{"id":"1PfGjljRO9Kj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bvMTasNQ7VTK"},"outputs":[],"source":["for i in range(NoOfData):\n","    \n","    # Declare temporary data (only sensor signals)\n","    exec(\"temp_data1 = Normal_%d.iloc[:,1:]\"%(i+1))\n","    exec(\"temp_data2 = Abnormal_%d.iloc[:,1:]\"%(i+1))\n","    \n","    # Walvelet decomposition\n","    Coef1 = pywt.wavedec(temp_data1, MotherWavelet, level=Level, axis=0)\n","    Coef2 = pywt.wavedec(temp_data2, MotherWavelet, level=Level, axis=0)\n","    \n","    # Frequency domain feature extraction\n","    for j in range(NoOfSensor):\n","        \n","        for k in np.arange(Level):\n","            coef1 = Coef1[Level-k]\n","            coef2 = Coef2[Level-k]\n","            \n","            ##################################################\n","            # Complete code below to obtain proper features\n","            # Tip: Use NoOfFeature, Level, j, and k\n","            ##################################################\n","\n","            # Normal features\n","            FreqFeature_Normal[ , i] = np.max(coef1[:,j])\n","            FreqFeature_Normal[ , i] = np.min(coef1[:,j])\n","            FreqFeature_Normal[ , i] = np.mean(coef1[:,j])\n","            FreqFeature_Normal[ , i] = rms(coef1[:,j])\n","            FreqFeature_Normal[ , i] = np.var(coef1[:,j])\n","            FreqFeature_Normal[ , i] = sp.skew(coef1[:,j])\n","            FreqFeature_Normal[ , i] = sp.kurtosis(coef1[:,j])\n","            FreqFeature_Normal[ , i] = np.max(coef1[:,j])/rms(coef1[:,j])\n","            FreqFeature_Normal[ , i] = rms(coef1[:,j])/np.mean(np.abs(coef1[:,j]))\n","            FreqFeature_Normal[ , i] = np.max(coef1[:,j])/np.mean(np.abs(coef1[:,j]))\n","            \n","            # Abnormal features\n","            FreqFeature_Abnormal[ , i] = np.max(coef2[:,j])\n","            FreqFeature_Abnormal[ , i] = np.min(coef2[:,j])\n","            FreqFeature_Abnormal[ , i] = np.mean(coef2[:,j])\n","            FreqFeature_Abnormal[ , i] = rms(coef2[:,j])\n","            FreqFeature_Abnormal[ , i] = np.var(coef2[:,j])\n","            FreqFeature_Abnormal[ , i] = sp.skew(coef2[:,j])\n","            FreqFeature_Abnormal[ , i] = sp.kurtosis(coef2[:,j])\n","            FreqFeature_Abnormal[ , i] = np.max(coef2[:,j])/rms(coef2[:,j])\n","            FreqFeature_Abnormal[ , i] = rms(coef2[:,j])/np.mean(np.abs(coef2[:,j]))\n","            FreqFeature_Abnormal[ , i] = np.max(coef2[:,j])/np.mean(np.abs(coef2[:,j]))\n","\n","            ##################################################\n","            ##################################################\n","\n","print(FreqFeature_Normal.shape)\n","print(FreqFeature_Abnormal.shape)\n","\n","FreqFeature_Normal"]},{"cell_type":"markdown","metadata":{"id":"f0y6Tvcs7VTK"},"source":["### Combine Normal and Abnormal feature arrays\n","\n","* axis=0: combine rows\n","* axis=1: combine columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgaypQR87VTK"},"outputs":[],"source":["FreqFeature = np.concatenate([FreqFeature_Normal, FreqFeature_Abnormal] , axis=1)\n","FreqFeature.shape"]},{"cell_type":"markdown","metadata":{"id":"__81Usiu7VTL"},"source":[".\n","\n",".\n","\n",".\n","\n"]},{"cell_type":"markdown","metadata":{"id":"p8mDjxUI7VTL"},"source":["## Final Feature Dataset \n","- (30 Time domain features + 240 Frequency domain features = 270 features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOa-PYnQ7VTL"},"outputs":[],"source":["Features = np.concatenate([TimeFeature,FreqFeature] , axis=0)\n","\n","print(Features.shape)\n","Features"]},{"cell_type":"markdown","metadata":{"id":"mK8jxNVP7VTL"},"source":["### Convert Array into Data frame format\n","\n","* Easy to save as data file (csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEp3fD737VTM"},"outputs":[],"source":["Features_df = pd.DataFrame(Features)\n","Features_df"]},{"cell_type":"markdown","metadata":{"id":"laqnBsXZ7VTM"},"source":["### Save Final Feature Data in Drive (.csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8KVfNCxo7VTM"},"outputs":[],"source":["path = '/content/drive/MyDrive/Colab Notebooks/SavedFiles/FeatureData.csv' \n","Features_df.to_csv(path, sep=',', header=None , index=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDqQq3T-7VTM"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}